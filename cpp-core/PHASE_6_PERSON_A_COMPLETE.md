# Phase 6 - Person A Complete: C++ Model Contract & Mapping (8‚Üí7 Dimensions)

**Date**: November 10, 2025  
**Phase**: 6 (Audio Synthesis & Full Pipeline Test)  
**Implementer**: Person A  
**Status**: ‚úÖ COMPLETE

---

## Summary

Person A has successfully updated the entire C++ codebase to handle the new **8-dimensional image features ‚Üí 7-dimensional music parameters** contract that matches the Phase 5.5 Python ML pipeline.

All code compiles and runs correctly. The heuristic mapping produces identical results to Python. Ready for Person B to redesign the AudioEngine.

---

## Changes Made

### A1. ImageFeatures Struct (8 dimensions)

**File**: `cpp-core/include/ImageFeatures.hpp`

```cpp
struct ImageFeatures {
    float avgR;         // [0] 0‚Äì1 (average red channel)
    float avgG;         // [1] 0‚Äì1 (average green channel)
    float avgB;         // [2] 0‚Äì1 (average blue channel)
    float brightness;   // [3] 0‚Äì1 (mean luminance)
    float hue;          // [4] 0‚Äì1 (HSV hue, normalized)
    float saturation;   // [5] 0‚Äì1 (HSV saturation)
    float colorfulness; // [6] 0‚Äì1 (Hasler & S√ºsstrunk metric)
    float contrast;     // [7] 0‚Äì1 (grayscale std dev, normalized)
};
```

**Previous**: 4 fields (avgR, avgG, avgB, brightness)  
**Current**: 8 fields (added hue, saturation, colorfulness, contrast)

---

### A2. Feature Extractor Implementation

**File**: `cpp-core/src/ImageFeatures.cpp`

**New Capabilities**:

1. **RGB ‚Üí HSV Conversion**
   - Implemented `rgbToHsv()` helper function
   - Computes hue [0-360¬∞] and saturation [0-1] per pixel
   - Averages across all pixels and normalizes hue to [0-1]

2. **Colorfulness Metric** (Hasler & S√ºsstrunk 2003)
   - Opponent color space: `rg = R - G`, `yb = 0.5*(R+G) - B`
   - Formula: `sqrt(std_rg¬≤ + std_yb¬≤) + 0.3*sqrt(mean_rg¬≤ + mean_yb¬≤)`
   - Normalized to [0-1] by dividing by 100 and clamping

3. **Contrast Computation**
   - Grayscale conversion: `gray = 0.299*R + 0.587*G + 0.114*B`
   - Standard deviation of grayscale values
   - Already normalized to [0-1] due to input normalization

**Algorithm Matches Python**: All formulas ported exactly from Python `feature_extractor.py`

**Test Result** (solid red image):
```
avgR         = 1.000000
avgG         = 0.000000
avgB         = 0.000000
brightness   = 0.333333
hue          = 0.000000  (red)
saturation   = 1.000000  (fully saturated)
colorfulness = 0.003354  (low colorfulness for solid color)
contrast     = 0.000104  (near zero for uniform image)
```

‚úÖ Matches Python output exactly!

---

### A3. MusicParameters Struct (7 dimensions)

**File**: `cpp-core/include/AudioEngine.hpp`

```cpp
struct MusicParameters {
    float tempoBpm;        // 40‚Äì90 BPM (slow ambient range)
    float baseFrequency;   // 100‚Äì400 Hz (bass to mid range)
    float energy;          // 0‚Äì1 (texture density/busyness)
    float brightness;      // 0‚Äì1 (filter cutoff, waveform choice)
    float reverb;          // 0‚Äì1 (dry to big hall)
    int   scaleType;       // 0=major, 1=minor, 2=dorian, 3=lydian
    int   patternType;     // 0=pad, 1=arp, 2=chords
};
```

**Previous**: 5 fields (tempoBpm, baseFrequency, brightness, volume, durationSeconds)  
**Current**: 7 fields (removed volume/duration, added energy, reverb, scaleType, patternType)

---

### A4. ModelClient Update (8‚Üí7 Contract)

**File**: `cpp-core/src/ModelClient.cpp`

**Input Payload** (8-dim):
```cpp
payload["instances"].push_back({
    f.avgR,
    f.avgG,
    f.avgB,
    f.brightness,
    f.hue,
    f.saturation,
    f.colorfulness,
    f.contrast
});
```

**Output Parsing** (7-dim):
```cpp
params.tempoBpm      = static_cast<float>(pred[0].get<double>());
params.baseFrequency = static_cast<float>(pred[1].get<double>());
params.energy        = static_cast<float>(pred[2].get<double>());
params.brightness    = static_cast<float>(pred[3].get<double>());
params.reverb        = static_cast<float>(pred[4].get<double>());

// Round discrete controls to nearest int
params.scaleType     = static_cast<int>(std::round(pred[5].get<double>()));
params.patternType   = static_cast<int>(std::round(pred[6].get<double>()));
```

**JSON Contract**: `{"instances": [[8 floats]]}` ‚Üí `{"predictions": [[7 floats]]}`

‚úÖ Compatible with Phase 5.5 Python TF Serving contract

---

### A5. Heuristic Mapping (Python ‚Üí C++ Port)

**File**: `cpp-core/src/MusicMapping.cpp`

**Complete Python Logic Ported**:

```cpp
// TEMPO: brightness ‚Üí speed, contrast ‚Üí boost
float tempo = 40.0f + brightness * 50.0f + contrast * 10.0f;
p.tempoBpm = clamp(tempo, 40.0f, 90.0f);

// BASE FREQUENCY: color temperature (R vs B)
float warmth = (avgR - avgB + 1.0f) / 2.0f;
p.baseFrequency = 100.0f + warmth * 300.0f;

// ENERGY: saturation + colorfulness
p.energy = clamp01(saturation * 0.6f + colorfulness * 0.4f);

// BRIGHTNESS: direct mapping
p.brightness = brightness;

// REVERB: inverted brightness + desaturation
float reverb = (1.0f - brightness) * 0.7f + (1.0f - saturation) * 0.3f;
p.reverb = clamp01(reverb);

// SCALE TYPE: hue-based
if      (hue < 0.15f) p.scaleType = 0;  // Major (red/orange)
else if (hue < 0.45f) p.scaleType = 3;  // Lydian (yellow/green)
else if (hue < 0.65f) p.scaleType = 1;  // Minor (blue)
else                  p.scaleType = 2;  // Dorian (purple)

// PATTERN TYPE: energy thresholds
if      (p.energy < 0.35f) p.patternType = 0;  // Pad
else if (p.energy < 0.70f) p.patternType = 1;  // Arp
else                       p.patternType = 2;  // Chords
```

**Model-Based Mapping** (with safety clamping):
```cpp
MusicParameters fromModel = client.predict(features);

// Safety net: clamp all values to valid ranges
fromModel.tempoBpm      = clamp(fromModel.tempoBpm, 40.0f, 90.0f);
fromModel.baseFrequency = clamp(fromModel.baseFrequency, 100.0f, 400.0f);
fromModel.energy        = clamp01(fromModel.energy);
fromModel.brightness    = clamp01(fromModel.brightness);
fromModel.reverb        = clamp01(fromModel.reverb);
fromModel.scaleType     = std::clamp(fromModel.scaleType, 0, 3);
fromModel.patternType   = std::clamp(fromModel.patternType, 0, 2);
```

**Test Result** (solid red image, heuristic mode):
```
tempoBpm      = 56.67 BPM    ‚úÖ Dark ‚Üí slow
baseFrequency = 400 Hz       ‚úÖ Warm (red) ‚Üí high freq
energy        = 0.601        ‚úÖ High saturation ‚Üí medium energy
brightness    = 0.333        ‚úÖ Matches visual brightness
reverb        = 0.467        ‚úÖ Dark ‚Üí moderate reverb
scaleType     = 0 (Major)    ‚úÖ Red ‚Üí Major scale
patternType   = 1 (Arp)      ‚úÖ Medium energy ‚Üí Arp pattern
```

‚úÖ Exact match with Python `map_features_to_music()`!

---

### A6. Enhanced Logging

**File**: `cpp-core/src/main.cpp`

**Image Features Output** (8-dim):
```cpp
std::cout << "Image features (8-dim):\n"
          << "  avgR         = " << features.avgR << "\n"
          << "  avgG         = " << features.avgG << "\n"
          << "  avgB         = " << features.avgB << "\n"
          << "  brightness   = " << features.brightness << "\n"
          << "  hue          = " << features.hue << "\n"
          << "  saturation   = " << features.saturation << "\n"
          << "  colorfulness = " << features.colorfulness << "\n"
          << "  contrast     = " << features.contrast << std::endl;
```

**Music Parameters Output** (7-dim with human-readable names):
```cpp
const char* scaleNames[] = {"Major", "Minor", "Dorian", "Lydian"};
const char* patternNames[] = {"Pad", "Arp", "Chords"};

std::cout << "Music parameters (7-dim):\n"
          << "  tempoBpm      = " << params.tempoBpm << " BPM\n"
          << "  baseFrequency = " << params.baseFrequency << " Hz\n"
          << "  energy        = " << params.energy << "\n"
          << "  brightness    = " << params.brightness << "\n"
          << "  reverb        = " << params.reverb << "\n"
          << "  scaleType     = " << params.scaleType << " (" << scaleName << ")\n"
          << "  patternType   = " << params.patternType << " (" << patternName << ")"
          << std::endl;
```

**Example Output**:
```
Music parameters (7-dim):
  tempoBpm      = 56.6677 BPM
  baseFrequency = 400 Hz
  energy        = 0.601342
  brightness    = 0.333333
  reverb        = 0.466667
  scaleType     = 0 (Major)
  patternType   = 1 (Arp)
```

---

### A7. HTTP Server Update

**File**: `cpp-core/src/HttpServer.cpp`

**Updated JSON Response**:
```cpp
resp["params"] = {
    {"tempoBpm",      params.tempoBpm},
    {"baseFrequency", params.baseFrequency},
    {"energy",        params.energy},
    {"brightness",    params.brightness},
    {"reverb",        params.reverb},
    {"scaleType",     params.scaleType},
    {"patternType",   params.patternType}
};
```

**Previous**: 5 parameters (tempo, baseFreq, brightness, volume, duration)  
**Current**: 7 parameters (tempo, baseFreq, energy, brightness, reverb, scaleType, patternType)

---

### A8. AudioEngine Placeholder

**File**: `cpp-core/src/AudioEngine.cpp`

**Status**: ‚ö†Ô∏è PLACEHOLDER for Person B

Current implementation:
- Fixed 10-second duration
- Simple sine wave synthesis
- Uses `baseFrequency` and `brightness` only
- **Does NOT implement**: scale types, pattern types, reverb, energy

**TODO for Person B**:
```cpp
// TODO: Person B - implement:
// - Scale intervals (major/minor/dorian/lydian)
// - Pattern types (pad/arp/chords)
// - Reverb effect (feedback delay)
// - Energy ‚Üí note density/complexity
// - Brightness ‚Üí filter cutoff/waveform mix
```

**Why Placeholder?**: Person B is responsible for full audio synthesis redesign. Person A focused on data structures and contract alignment only.

---

## Testing & Validation

### Compilation
```bash
cd cpp-core/build
cmake ..
make -j4
```
‚úÖ **Result**: Clean compilation, no errors

### Heuristic Mode Test
```bash
./soundcanvas_core --mode=heuristic ../examples/test_image.png output.wav
```

**Input**: Solid red PNG (1x1 pixel)

**Features Extracted**:
```
avgR         = 1.0
avgG         = 0.0
avgB         = 0.0
brightness   = 0.333
hue          = 0.0
saturation   = 1.0
colorfulness = 0.003
contrast     = 0.0001
```

**Parameters Generated**:
```
tempoBpm      = 56.67 BPM
baseFrequency = 400 Hz
energy        = 0.601
brightness    = 0.333
reverb        = 0.467
scaleType     = 0 (Major)
patternType   = 1 (Arp)
```

‚úÖ **Result**: WAV file generated successfully, parameters match Python exactly

---

## Contract Alignment Checklist

### With Python ML Pipeline (Phase 5.5)

| Component | Python | C++ | Status |
|-----------|--------|-----|--------|
| **Input Features** | 8-dim | 8-dim | ‚úÖ Aligned |
| **Feature Order** | [avgR, avgG, avgB, brightness, hue, sat, color, contrast] | Same | ‚úÖ Aligned |
| **Output Parameters** | 7-dim | 7-dim | ‚úÖ Aligned |
| **Parameter Order** | [tempo, baseFreq, energy, brightness, reverb, scale, pattern] | Same | ‚úÖ Aligned |
| **Heuristic Logic** | Python formulas | Ported to C++ | ‚úÖ Aligned |
| **Value Ranges** | 40-90 BPM, 100-400 Hz, etc. | Same | ‚úÖ Aligned |

### With TF Serving API

| Component | Expected | Actual | Status |
|-----------|----------|--------|--------|
| **Request Format** | `{"instances": [[8 floats]]}` | Same | ‚úÖ Aligned |
| **Response Format** | `{"predictions": [[7 floats]]}` | Same | ‚úÖ Aligned |
| **Discrete Params** | Floats (will round) | Round to int | ‚úÖ Aligned |

---

## File Summary

### Modified Files (7)
1. ‚úÖ `include/ImageFeatures.hpp` - 8-dim struct
2. ‚úÖ `src/ImageFeatures.cpp` - Full feature extraction
3. ‚úÖ `include/AudioEngine.hpp` - 7-dim struct
4. ‚úÖ `src/AudioEngine.cpp` - Placeholder synthesis
5. ‚úÖ `src/ModelClient.cpp` - 8‚Üí7 JSON contract
6. ‚úÖ `src/MusicMapping.cpp` - Python logic port
7. ‚úÖ `src/main.cpp` - Enhanced logging
8. ‚úÖ `src/HttpServer.cpp` - Updated JSON response

### Lines Changed
- **Added**: ~200 lines (feature extraction, mapping logic)
- **Modified**: ~100 lines (struct updates, parameter handling)
- **Total**: ~300 lines of code changes

---

## Handoff to Person B

### What Person A Completed ‚úÖ

1. **Data Structures**: All structs updated to 8‚Üí7 dimensions
2. **Feature Extraction**: Complete HSV, colorfulness, contrast implementation
3. **Model Contract**: TF Serving communication handles new dimensions
4. **Heuristic Mapping**: Exact Python logic ported to C++
5. **Safety Clamping**: All parameters bounded to valid ranges
6. **Logging**: Comprehensive output for debugging
7. **HTTP API**: Updated to return new 7-dim parameters

### What Person B Needs to Do üîÑ

Person B is responsible for **AudioEngine redesign** to actually use the new parameters:

#### B1. Scale Implementation
```cpp
// Define scale intervals for each scaleType
std::vector<int> getScaleSemitones(int scaleType) {
    switch (scaleType) {
        case 0: return {0, 2, 4, 5, 7, 9, 11};      // Major
        case 1: return {0, 2, 3, 5, 7, 8, 10};      // Minor
        case 2: return {0, 2, 3, 5, 7, 9, 10};      // Dorian
        case 3: return {0, 2, 4, 6, 7, 9, 11};      // Lydian
    }
}
```

#### B2. Pattern Types
- **Pad** (0): Sustained 1-2 note drones, slow LFO
- **Arp** (1): Arpeggiate scale degrees, tempo-synced
- **Chords** (2): Block chords, rhythmic changes

#### B3. Reverb Effect
- Simple feedback delay line
- `reverb` parameter controls wet/dry mix

#### B4. Energy Control
- Low energy ‚Üí fewer notes, simpler patterns
- High energy ‚Üí more notes, complex textures

#### B5. Brightness Control
- Low brightness ‚Üí darker waveforms (sine, filtered saw)
- High brightness ‚Üí brighter waveforms (saw, square, unfiltered)

See `PHASE_6_INSTRUCTIONS.md` for Person B's detailed task list.

---

## Next Steps

### For Person B:
1. Read Phase 6 instructions (Person B section)
2. Implement scale/pattern/reverb in `AudioEngine.cpp`
3. Test with diverse images (bright/dark, blue/red, saturated/desaturated)
4. Listen and verify musical coherence

### For Integration Testing:
1. Ensure Python TF Serving is running with Phase 5.5 model
2. Test `--mode=model` with C++ client
3. Verify HTTP server mode works end-to-end
4. Test with gateway + database (Phase 5 integration)

### Success Criteria:
- [ ] Dark images ‚Üí slow tempo, high reverb, pads
- [ ] Bright images ‚Üí faster tempo, low reverb, arps/chords
- [ ] Blue images ‚Üí minor scale, low frequencies
- [ ] Red images ‚Üí major scale, high frequencies
- [ ] No clipping or harsh noise
- [ ] All 7 parameters audibly affect output

---

## Known Issues / Notes

### ‚ö†Ô∏è AudioEngine is Placeholder
Current implementation only uses `baseFrequency` and `brightness`. Other parameters are ignored until Person B implements them.

### ‚úÖ All Contracts Aligned
Python ML pipeline, TF Serving API, and C++ client all agree on 8‚Üí7 dimensions.

### ‚úÖ Tested & Working
Heuristic mode produces correct parameters. Ready for model-based testing once TF Serving is updated.

---

## Commands Reference

### Build
```bash
cd cpp-core/build
cmake ..
make -j4
```

### Test Heuristic Mode
```bash
./soundcanvas_core --mode=heuristic ../examples/image.jpg output.wav
```

### Test Model Mode (requires TF Serving)
```bash
export SC_TF_SERVING_URL="http://localhost:8501/v1/models/soundcanvas:predict"
./soundcanvas_core --mode=model ../examples/image.jpg output.wav
```

### HTTP Server Mode
```bash
export SC_DEFAULT_MODE="model"
export SC_OUTPUT_DIR="../examples"
./soundcanvas_core --serve
```

Then POST to:
```bash
curl -X POST http://localhost:8080/generate \
  -H "Content-Type: application/json" \
  -d '{"image_path": "../examples/image.jpg", "mode": "model"}'
```

---

**Status**: ‚úÖ Person A tasks COMPLETE  
**Next**: Person B audio synthesis implementation  
**Blockers**: None - ready for Person B to proceed

---

**End of Person A Summary - Phase 6**
